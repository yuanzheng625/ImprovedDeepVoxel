{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz37dAz5Xi_q"
      },
      "source": [
        "# TensorRT\n",
        "\n",
        "In this notebook, we will use TensorRT to optimize a PyTorch model for inference. We will train a simple CNN model on the MNIST dataset, convert it to TensorRT engine using ONNX, and then perform inference using the optimized TensorRT engine model and evaluate the size and accuracy of the model. This notebook require a NVIDIA GPU with CUDA support or NVIDIA Jetson device."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC1lpU_TXi_q"
      },
      "source": [
        "## Setup TensorRT\n",
        "\n",
        "First, install tensorrt and torch using pip and import the neccesary modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cqpq6QptXi_r",
        "outputId": "1d005053-a913-4385-d445-2593ed38c810",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: torchvision==0.2.2 in /usr/local/lib/python3.11/dist-packages (0.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==1.13.1) (4.13.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.1) (11.7.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.2.2) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from torchvision==0.2.2) (1.17.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.2.2) (11.1.0)\n",
            "Requirement already satisfied: tqdm==4.19.9 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.2.2) (4.19.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.45.1)\n",
            "Requirement already satisfied: tensorrt==8.6.1 in /usr/local/lib/python3.11/dist-packages (8.6.1)\n",
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.11/dist-packages (2025.1)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.11/dist-packages (1.21.0)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.11/dist-packages (from pycuda) (2025.1.2)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.7)\n",
            "Requirement already satisfied: mako in /usr/lib/python3/dist-packages (from pycuda) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.13.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Requirement already satisfied: pytorch-quantization==2.1.2 in /usr/local/lib/python3.11/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pytorch-quantization==2.1.2) (2.0.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-quantization==2.1.2) (1.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pytorch-quantization==2.1.2) (1.14.1)\n",
            "Requirement already satisfied: sphinx-glpi-theme in /usr/local/lib/python3.11/dist-packages (from pytorch-quantization==2.1.2) (0.6)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.11/dist-packages (from pytorch-quantization==2.1.2) (3.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from pytorch-quantization==2.1.2) (6.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable->pytorch-quantization==2.1.2) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "%pip install torch==1.13.1 torchvision==0.2.2\n",
        "%pip install tensorrt==8.6.1\n",
        "%pip install pycuda onnx onnxruntime\n",
        "%pip install --no-cache-dir --extra-index-url https://pypi.nvidia.com pytorch-quantization==2.1.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow==6.1"
      ],
      "metadata": {
        "id": "t3RGaa0lbPUt",
        "outputId": "b2e13dd5-b32a-4294-f9c0-4de8ae90d6b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow==6.1 in /usr/local/lib/python3.11/dist-packages (6.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3Gr4ez2BXi_r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.quantization\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import torch.onnx\n",
        "import tensorrt as trt\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import onnx\n",
        "import onnxruntime\n",
        "\n",
        "from pytorch_quantization import nn as quant_nn\n",
        "from pytorch_quantization import quant_modules\n",
        "from pytorch_quantization import calib\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErB82BcJXi_r"
      },
      "source": [
        "## Train PyTorch Model and Export to ONNX\n",
        "\n",
        "Next, train a simple CNN model on the MNIST dataset and export it to ONNX format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "C4w-t8vjXi_r",
        "outputId": "3b671826-d1ff-495a-8dea-d05c9c845412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /content/data/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "Extracting /content/data/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "Using downloaded and verified file: /content/data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting /content/data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Using downloaded and verified file: /content/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Extracting /content/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Using downloaded and verified file: /content/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting /content/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 16: b''",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-f7996b94beea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         ])\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         training_set = (\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mread_image_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train-images-idx3-ubyte'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mread_label_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train-labels-idx1-ubyte'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36mread_image_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mget_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2051\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mnum_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36mget_int\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 16: b''"
          ]
        }
      ],
      "source": [
        "transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "\n",
        "train_dataset = datasets.MNIST('/content/data', train=True, download=True,transform=transform)\n",
        "test_dataset = datasets.MNIST('/content/data', train=False,transform=transform)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=12, kernel_size=3)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc = nn.Linear(12 * 13 * 13, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1, 28, 28)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, 32)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, 32)\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "            100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "MODEL_DIR = pathlib.Path(\"./models\")\n",
        "MODEL_DIR.mkdir(exist_ok=True)\n",
        "torch.save(model.state_dict(), MODEL_DIR / \"original_model.p\")\n",
        "\n",
        "x, _ = next(iter(train_loader))\n",
        "torch.onnx.export(model,\n",
        "                  x,\n",
        "                  MODEL_DIR / \"mnist_model.onnx\",\n",
        "                  export_params=True,\n",
        "                  opset_version=10,\n",
        "                  do_constant_folding=True,\n",
        "                  input_names = ['input'],\n",
        "                  output_names = ['output'],\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},\n",
        "                                'output' : {0 : 'batch_size'}})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/data/MNIST/raw/train-images-idx3-ubyte /content/data/MNIST/raw/train-images-idx3-ubyte.gz"
      ],
      "metadata": {
        "id": "BiQEGba1b0Vw",
        "outputId": "98db4380-86fe-420a-bee9-5249543dd2c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/data/MNIST/raw/train-images-idx3-ubyte': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/data/MNIST/raw/train-labels-idx1-ubyte /content/data/MNIST/raw/train-labels-idx1-ubyte.gz"
      ],
      "metadata": {
        "id": "s1GXxkN1c2NZ",
        "outputId": "dcd80b83-dee7-43b0-8cbb-34b2863eb5aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/data/MNIST/raw/train-labels-idx1-ubyte': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/data/MNIST/raw/t10k-labels-idx1-ubyte /content/data/MNIST/raw/t10k-labels-idx1-ubyte.gz"
      ],
      "metadata": {
        "id": "ejkYHymbdASx",
        "outputId": "6b30c80a-ce7e-42d2-9629-a73dc3c9159c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/data/MNIST/raw/t10k-labels-idx1-ubyte': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqX7YWI2Xi_r"
      },
      "source": [
        "## Convert ONNX Model to TensorRT\n",
        "\n",
        "To convert the ONNX model to TensorRT engine using the TensorRT Python API. First, initialize TensorRT components which are logger, builder, and network. Next, define ONNX parser to parse the ONNX model from the ONNX file into the TensorRT network. Then, create a builder configuration to set building parameters and a memory pool limit for the workspace in TensorRT. Then, create an optimization profile to handle dynamic input shapes with batch size of 32, channel size of 1, and image dimensions of 28x28. Next, built and serialized the TensorRT engine using the configured network and builder and then saved to disk. Finally, the script cleans up by deleting the builder and network objects to free up resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAmLBuHrXi_r"
      },
      "outputs": [],
      "source": [
        "onnx_path = MODEL_DIR / \"mnist_model.onnx\"\n",
        "trt_path = MODEL_DIR / 'mnist_engine_pytorch.trt'\n",
        "\n",
        "# initialize TensorRT engine and parse ONNX model\n",
        "logger = trt.Logger(trt.Logger.WARNING)\n",
        "builder = trt.Builder(logger)\n",
        "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
        "\n",
        "parser = trt.OnnxParser(network, logger)\n",
        "parser.parse_from_file(str(onnx_path))\n",
        "\n",
        "# set up the builder config and coptimization profile\n",
        "config = builder.create_builder_config()\n",
        "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)\n",
        "\n",
        "profile = builder.create_optimization_profile()\n",
        "profile.set_shape(\"input\", (32, 1, 28, 28), (32, 1, 28, 28), (32, 1, 28, 28))\n",
        "config.add_optimization_profile(profile)\n",
        "\n",
        "# serialize the engine, then save to disk\n",
        "serialized_engine = builder.build_serialized_network(network, config)\n",
        "with open(str(trt_path), 'wb') as f:\n",
        "    f.write(serialized_engine)\n",
        "\n",
        "# free up resources\n",
        "del builder\n",
        "del network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zej174dTXi_r"
      },
      "source": [
        "## Run Inference and Check Accuracy\n",
        "\n",
        "Finally, run inference and then compare the TensorRT engine model accuracy with the ONNX model on the test dataset.\n",
        "\n",
        "To run test ONNX model, load the model and test model model integrity and then loop over the given Data Loader, For each batch, convert the input data to a NumPy array and fed into the ONNX Runtime session. Once, obtained the output convert back to a PyTorch tensor. Then, calculate the accumulated negative log likelihood loss\n",
        "and number of correct predictions to measure the accuracy of the model.\n",
        "\n",
        "To test the tensorRT model, first, load the serialized engine from disk, and initialize TensorRT runtime. Then, deserialized the engine and create execution context is created. Next, allocate memory for input and output data on the GPU, set bindings for the TensorRT execution and create CUDA stream to manage asynchronous data transfers between the CPU and GPU. Then, Loop over the given Data Loader and for each batch, convert the input data to a NumPy array and transfer to the GPU, before executing the model asynchronously, and then transfer the predictions back to the CPU. Run synchronization to ensures proper coordination between threads. Next, reshaped output and convert to a PyTorch tensor to calculate the accumulated negative log likelihood loss and number of correct predictions to measure the accuracy of the model. Finally, free up the memory and CUDA resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KO5mBWH8Xi_s"
      },
      "outputs": [],
      "source": [
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "def test_onnx(model_name, data_loader):\n",
        "    onnx_model = onnx.load(model_name)\n",
        "    onnx.checker.check_model(onnx_model)\n",
        "    ort_session = onnxruntime.InferenceSession(model_name)\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in data_loader:\n",
        "        ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(data)}\n",
        "        output = ort_session.run(None, ort_inputs)[0]\n",
        "        output = torch.from_numpy(output)\n",
        "        if target.shape[0] == 32: # last batch might be smaller than 32 (quick fix)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(data_loader.dataset)\n",
        "    return 100. * correct / len(data_loader.dataset)\n",
        "\n",
        "def test_tensorrt(model_name, data_loader):\n",
        "    with open(model_name, \"rb\") as f:\n",
        "        serialized_engine = f.read()\n",
        "    runtime = trt.Runtime(logger)\n",
        "    engine = runtime.deserialize_cuda_engine(serialized_engine)\n",
        "    context = engine.create_execution_context()\n",
        "    input_size = trt.volume(engine.get_binding_shape(0))\n",
        "    output_size = trt.volume(engine.get_binding_shape(1))\n",
        "    # Allocate device memory\n",
        "    d_input = cuda.mem_alloc(input_size * 4)  # Assuming 4-byte float32 data type\n",
        "    d_output = cuda.mem_alloc(output_size * 4)\n",
        "    bindings=[int(d_input), int(d_output)]\n",
        "    stream = cuda.Stream()\n",
        "    h_output = np.empty(output_size, dtype=np.float32)\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in data_loader:\n",
        "        # Create numpy arrays to hold input and output data\n",
        "        h_input = data.numpy().astype(np.float32)\n",
        "        # Transfer input data to device\n",
        "        cuda.memcpy_htod_async(d_input, h_input, stream)\n",
        "        # Execute model\n",
        "        context.execute_async_v2(bindings, stream.handle, None)\n",
        "        # Transfer predictions back\n",
        "        cuda.memcpy_dtoh_async(h_output, d_output, stream)\n",
        "        # Syncronize threads\n",
        "        stream.synchronize()\n",
        "        output = h_output.reshape(context.get_tensor_shape('output'))\n",
        "        output = torch.from_numpy(output)\n",
        "        if target.shape[0] == 32: # last batch might be smaller than 32 (quick fix)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(data_loader.dataset)\n",
        "    del context\n",
        "    del engine\n",
        "    cuda.Context.pop()\n",
        "    return 100. * correct / len(data_loader.dataset)\n",
        "\n",
        "acc = test_onnx(onnx_path, test_loader)\n",
        "print(f\"Accuracy of the onnx model is {acc}%\")\n",
        "\n",
        "trtr_acc = test_tensorrt(trt_path, test_loader)\n",
        "print(f\"Accuracy of the tensorrt model is {trtr_acc}%\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}